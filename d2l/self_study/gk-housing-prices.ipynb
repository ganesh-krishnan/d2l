{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import np, npx, autograd\n",
    "from mxnet.gluon import nn, Trainer\n",
    "from mxnet.gluon.loss import L2Loss\n",
    "from mxnet import initializer\n",
    "from d2l import mxnet as d2l\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from pdb import set_trace\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_df = pd.read_csv(d2l.download('kaggle_house_train'))\n",
    "score_df = pd.read_csv(d2l.download('kaggle_house_test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(base_train_df, train_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = train_df.columns[train_df.dtypes == 'object'].tolist()\n",
    "numeric_cols = [col for col in train_df.columns[train_df.dtypes != 'object'].tolist() if col != 'Id']\n",
    "cat_transformer = Pipeline(steps=[('impute', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                  ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "numeric_transformer = Pipeline(steps=[('impute', SimpleImputer(strategy='median')),\n",
    "                                      ('scale', StandardScaler())])\n",
    "preprocessor = ColumnTransformer([('cat', cat_transformer, cat_cols),\n",
    "                                  ('numeric', numeric_transformer, numeric_cols)])\n",
    "pipe = Pipeline(steps=[('preprocess', preprocessor)])\n",
    "pipe.fit(train_df)\n",
    "train_X = pipe.transform(train_df).toarray()\n",
    "train_y = train_df.SalePrice.to_numpy()\n",
    "test_X = pipe.transform(test_df).toarray()\n",
    "test_y = test_df.SalePrice.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mxnet_array(*arr):\n",
    "    output_list = []\n",
    "    for array in arr:\n",
    "        output_list.append(np.array(array).astype('float32'))\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = convert_to_mxnet_array(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(256, activation='relu'))\n",
    "    net.add(nn.Dropout(0.5))\n",
    "    net.add(nn.Dense(256, activation='relu'))\n",
    "    net.add(nn.Dropout(0.1))\n",
    "    net.add(nn.Dense(1))\n",
    "net.initialize(initializer.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = L2Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(yhat, y):\n",
    "    log_yhat = np.log(yhat)\n",
    "    log_y = np.log(y)\n",
    "    return np.sqrt(L2Loss()(log_yhat, log_y).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1\n",
    "wd = 10\n",
    "num_epochs = 50\n",
    "optimizer = Trainer(net.collect_params(), optimizer='adam', optimizer_params={'learning_rate': lr, 'wd': wd})\n",
    "net.collect_params('.*bias').setattr('wd_mult', 0)\n",
    "for epoch in range(num_epochs):\n",
    "    with autograd.record():\n",
    "        yhat = net(train_X).squeeze()\n",
    "        loss = loss_fn(yhat, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step(batch_size=train_X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.13793813)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(net(test_X), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7696462e+07, 8.0826672e+07, 9.5196608e+07, 2.6123574e+07,\n",
       "       6.7614342e+08, 4.4429156e+07, 3.6750576e+07, 8.9169300e+06,\n",
       "       2.6867070e+06, 9.6389888e+07, 3.1910062e+05, 3.0337182e+07,\n",
       "       1.1799840e+06, 2.4409278e+08, 4.9052995e+06, 1.4967662e+08,\n",
       "       2.3177304e+07, 2.6373508e+06, 1.6102591e+07, 6.0623728e+07,\n",
       "       5.8405610e+06, 7.5160490e+06, 2.0727544e+07, 1.6197209e+07,\n",
       "       4.0214192e+07, 2.1611254e+07, 1.0528298e+08, 4.8029264e+07,\n",
       "       6.2785446e+08, 6.7300844e+05, 2.1020188e+06, 4.5757316e+07,\n",
       "       4.8714004e+07, 1.9913670e+07, 7.0581458e+09, 3.1139612e+05,\n",
       "       9.0582579e+08, 3.4602232e+07, 9.7083184e+07, 1.2210571e+08,\n",
       "       3.7017904e+07, 6.7296685e+08, 7.2630056e+07, 9.6010392e+07,\n",
       "       1.3169884e+06, 2.7419210e+07, 8.0027062e+05, 9.4668800e+05,\n",
       "       9.0105100e+06, 2.4919594e+07, 2.4912260e+06, 2.0907090e+08,\n",
       "       4.0909843e+08, 1.6217203e+08, 2.0867112e+07, 2.9546335e+06,\n",
       "       2.4071500e+07, 7.6771538e+05, 1.8930688e+08, 1.8314587e+08,\n",
       "       5.8877570e+06, 6.5874036e+07, 4.6163835e+06, 8.1006270e+06,\n",
       "       2.6482026e+07, 2.5995813e+08, 9.4377056e+07, 4.4492956e+07,\n",
       "       9.9011248e+07, 2.3885125e+06, 3.5940062e+06, 9.8679730e+06,\n",
       "       1.2828324e+09, 2.3269851e+08, 4.9805626e+08, 1.1848104e+07,\n",
       "       8.0415568e+07, 2.7582877e+08, 1.3510089e+07, 6.2092364e+07,\n",
       "       6.5709920e+06, 1.5238564e+09, 1.0240862e+08, 2.8745875e+08,\n",
       "       3.1249700e+07, 1.0761828e+07, 1.2544810e+08, 3.1163662e+07,\n",
       "       3.1873250e+07, 1.7280954e+07, 1.1334651e+08, 2.4075790e+08,\n",
       "       6.0513064e+07, 1.7133652e+07, 3.5238902e+04, 1.0385647e+08,\n",
       "       1.3497759e+06, 5.8209837e+08, 1.1535981e+07, 6.6786276e+07,\n",
       "       3.2437280e+08, 4.9043205e+06, 3.5177123e+08, 2.2400226e+08,\n",
       "       2.1787858e+08, 1.5292410e+08, 1.8556612e+07, 6.1711936e+08,\n",
       "       2.1033490e+07, 1.4120211e+07, 5.6501565e+06, 2.3983374e+08,\n",
       "       4.7461024e+08, 1.1206472e+08, 6.9621200e+07, 3.1034630e+08,\n",
       "       2.1349028e+03, 7.0490744e+07, 5.3598288e+07, 1.5174589e+08,\n",
       "       5.0667390e+06, 4.2965148e+07, 1.2530800e+07, 3.5489392e+07,\n",
       "       1.6270896e+08, 2.3852710e+08, 7.3322648e+07, 7.9615440e+07,\n",
       "       4.2642906e+08, 4.5611697e+05, 3.9620924e+07, 7.1623248e+07,\n",
       "       2.5058886e+07, 8.0880535e+06, 1.1966891e+08, 5.1891066e+08,\n",
       "       6.4938730e+06, 7.6325685e+06, 1.2451900e+06, 1.1970228e+07,\n",
       "       2.3627226e+07, 1.6757798e+08, 9.7492064e+07, 1.4520997e+09,\n",
       "       9.1296650e+06, 2.7767432e+07, 1.4419071e+09, 4.2830700e+06,\n",
       "       2.4184328e+07, 1.4613019e+08, 3.0468349e+08, 5.6447388e+07,\n",
       "       5.3353480e+07, 8.5994691e+09, 2.2025714e+07, 8.5737464e+07,\n",
       "       1.9383532e+07, 1.2812128e+08, 2.9431587e+08, 3.3936376e+07,\n",
       "       2.9263930e+08, 5.7918900e+07, 4.6819292e+07, 2.4120660e+06,\n",
       "       1.8360853e+05, 2.2150440e+07, 2.9128542e+07, 1.3181932e+06,\n",
       "       4.5259355e+06, 1.4969421e+08, 1.9107016e+07, 6.2977560e+06,\n",
       "       7.5616177e+03, 1.1142445e+04, 7.9641272e+07, 7.3493888e+07,\n",
       "       2.4010965e+06, 3.2795824e+07, 1.8189214e+07, 1.1323032e+08,\n",
       "       1.9923236e+07, 5.7803827e+08, 2.9234490e+08, 1.4729938e+07,\n",
       "       1.8381122e+07, 1.1245946e+08, 4.9021430e+08, 2.4252022e+07,\n",
       "       2.8252528e+07, 1.1174407e+07, 3.9525472e+08, 7.4058252e+03,\n",
       "       6.0385756e+07, 4.8325275e+06, 1.0505591e+06, 1.5459854e+11,\n",
       "       1.0700519e+08, 1.2716786e+08, 5.3103264e+11, 1.3898887e+07,\n",
       "       1.3246960e+08, 5.2107694e+05, 5.9354600e+07, 6.5032292e+07,\n",
       "       4.3671670e+06, 3.0473014e+08, 4.4198477e+08, 3.9232426e+08,\n",
       "       5.0862061e+08, 1.0201884e+09, 2.2802435e+08, 1.0673861e+08,\n",
       "       4.5596924e+07, 1.8590877e+09, 1.6680934e+09, 6.8580140e+06,\n",
       "       1.5011347e+07, 6.0169265e+06, 1.2413462e+06])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(net(test_X), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 129800.805,  135750.   ],\n",
       "       [ 140785.7  ,  153500.   ],\n",
       "       [  98298.305,   84500.   ],\n",
       "       [ 185228.22 ,  178000.   ],\n",
       "       [ 126773.45 ,   90000.   ],\n",
       "       [ 146926.47 ,  137500.   ],\n",
       "       [ 192673.28 ,  184100.   ],\n",
       "       [ 179223.02 ,  175000.   ],\n",
       "       [ 192318.06 ,  190000.   ],\n",
       "       [ 195384.52 ,  181500.   ],\n",
       "       [ 247529.12 ,  248328.   ],\n",
       "       [ 277210.62 ,  285000.   ],\n",
       "       [ 267536.22 ,  266000.   ],\n",
       "       [ 147805.08 ,  169900.   ],\n",
       "       [ 373032.2  ,  369900.   ],\n",
       "       [  43698.17 ,   61000.   ],\n",
       "       [ 185808.42 ,  179000.   ],\n",
       "       [ 228296.67 ,  226000.   ],\n",
       "       [ 105674.96 ,  100000.   ],\n",
       "       [ 126988.76 ,  138000.   ],\n",
       "       [ 150417.77 ,  147000.   ],\n",
       "       [ 243877.12 ,  240000.   ],\n",
       "       [ 445218.56 ,  438780.   ],\n",
       "       [ 145691.61 ,  140000.   ],\n",
       "       [ 108968.19 ,  100000.   ],\n",
       "       [ 125925.62 ,  132500.   ],\n",
       "       [ 254510.89 ,  240000.   ],\n",
       "       [ 115800.945,  106000.   ],\n",
       "       [ 225435.98 ,  190000.   ],\n",
       "       [ 116160.18 ,  115000.   ],\n",
       "       [ 131550.38 ,  129500.   ],\n",
       "       [ 133433.67 ,  143000.   ],\n",
       "       [ 130370.56 ,  120500.   ],\n",
       "       [ 147589.11 ,  153900.   ],\n",
       "       [ 273688.   ,  392500.   ],\n",
       "       [ 133289.17 ,  132500.   ],\n",
       "       [ 282249.5  ,  239686.   ],\n",
       "       [ 153318.92 ,  145000.   ],\n",
       "       [ 161334.36 ,  147400.   ],\n",
       "       [ 155627.27 ,  140000.   ],\n",
       "       [ 131295.6  ,  139900.   ],\n",
       "       [ 193313.03 ,  230000.   ],\n",
       "       [ 252052.39 ,  240000.   ],\n",
       "       [ 158642.84 ,  172500.   ],\n",
       "       [ 128122.95 ,  126500.   ],\n",
       "       [ 154344.7  ,  161750.   ],\n",
       "       [ 230734.88 ,  232000.   ],\n",
       "       [ 248624.   ,  250000.   ],\n",
       "       [ 114245.12 ,  110000.   ],\n",
       "       [ 142640.31 ,  149700.   ],\n",
       "       [ 153232.14 ,  151000.   ],\n",
       "       [ 189448.52 ,  169000.   ],\n",
       "       [ 187604.14 ,  159000.   ],\n",
       "       [ 111009.555,   93000.   ],\n",
       "       [ 162039.8  ,  168500.   ],\n",
       "       [ 114930.9  ,  112500.   ],\n",
       "       [ 198938.52 ,  192000.   ],\n",
       "       [ 166739.12 ,  165500.   ],\n",
       "       [ 403428.   ,  383970.   ],\n",
       "       [ 332138.75 ,  313000.   ],\n",
       "       [  96331.55 ,   92900.   ],\n",
       "       [ 286478.16 ,  275000.   ],\n",
       "       [ 177538.55 ,  174500.   ],\n",
       "       [ 194025.08 ,  190000.   ],\n",
       "       [ 160222.36 ,  167500.   ],\n",
       "       [ 197801.67 ,  175000.   ],\n",
       "       [ 145761.22 ,  159500.   ],\n",
       "       [ 145566.77 ,  155000.   ],\n",
       "       [ 184072.05 ,  170000.   ],\n",
       "       [ 140685.64 ,  138500.   ],\n",
       "       [ 137681.05 ,  135000.   ],\n",
       "       [ 183557.48 ,  188000.   ],\n",
       "       [ 172152.39 ,  121500.   ],\n",
       "       [ 253426.94 ,  275000.   ],\n",
       "       [ 193438.75 ,  225000.   ],\n",
       "       [  86632.125,   91500.   ],\n",
       "       [ 202518.08 ,  215200.   ],\n",
       "       [ 217688.39 ,  194201.   ],\n",
       "       [ 292198.1  ,  287000.   ],\n",
       "       [ 128143.82 ,  117000.   ],\n",
       "       [ 163825.19 ,  160200.   ],\n",
       "       [ 134793.9  ,  190000.   ],\n",
       "       [ 142688.56 ,  157000.   ],\n",
       "       [ 142977.44 ,  119000.   ],\n",
       "       [ 144810.66 ,  136905.   ],\n",
       "       [ 251660.64 ,  256300.   ],\n",
       "       [ 227839.7  ,  212000.   ],\n",
       "       [ 152894.77 ,  145000.   ],\n",
       "       [ 131615.86 ,  139600.   ],\n",
       "       [ 162810.94 ,  156932.   ],\n",
       "       [ 155056.33 ,  140000.   ],\n",
       "       [ 145556.53 ,  167500.   ],\n",
       "       [ 321001.2  ,  310000.   ],\n",
       "       [ 144046.17 ,  149900.   ],\n",
       "       [ 121734.52 ,  122000.   ],\n",
       "       [ 287087.75 ,  301500.   ],\n",
       "       [ 180543.03 ,  178900.   ],\n",
       "       [ 245379.67 ,  279500.   ],\n",
       "       [ 217696.67 ,  222500.   ],\n",
       "       [ 142557.36 ,  131000.   ],\n",
       "       [ 217529.52 ,  243000.   ],\n",
       "       [ 318631.88 ,  315500.   ],\n",
       "       [ 263024.38 ,  236500.   ],\n",
       "       [ 112166.12 ,   91000.   ],\n",
       "       [ 190874.8  ,  170000.   ],\n",
       "       [ 146511.48 ,  164000.   ],\n",
       "       [ 210907.94 ,  217000.   ],\n",
       "       [ 145368.27 ,  180500.   ],\n",
       "       [ 156414.1  ,  162900.   ],\n",
       "       [ 197350.83 ,  202665.   ],\n",
       "       [ 151638.4  ,  155000.   ],\n",
       "       [ 211268.69 ,  233170.   ],\n",
       "       [ 138690.58 ,  169500.   ],\n",
       "       [ 161029.05 ,  176000.   ],\n",
       "       [ 113199.9  ,  125000.   ],\n",
       "       [ 235913.7  ,  211000.   ],\n",
       "       [ 167934.66 ,  168000.   ],\n",
       "       [ 187373.56 ,  175500.   ],\n",
       "       [ 140253.58 ,  129900.   ],\n",
       "       [ 135421.02 ,  118000.   ],\n",
       "       [ 140816.69 ,  144000.   ],\n",
       "       [ 180730.14 ,  190000.   ],\n",
       "       [ 184606.16 ,  179600.   ],\n",
       "       [ 141424.89 ,  133000.   ],\n",
       "       [ 142039.34 ,  124000.   ],\n",
       "       [ 126741.57 ,  104900.   ],\n",
       "       [ 174890.28 ,  187000.   ],\n",
       "       [ 214381.33 ,  227000.   ],\n",
       "       [ 166703.73 ,  137500.   ],\n",
       "       [ 142955.11 ,  142000.   ],\n",
       "       [  73098.21 ,   82000.   ],\n",
       "       [ 261968.56 ,  250000.   ],\n",
       "       [ 237579.39 ,  230500.   ],\n",
       "       [ 163878.05 ,  167900.   ],\n",
       "       [ 242470.55 ,  227000.   ],\n",
       "       [ 177784.77 ,  210000.   ],\n",
       "       [ 123603.85 ,  120000.   ],\n",
       "       [ 135092.94 ,  139000.   ],\n",
       "       [ 139421.9  ,  141000.   ],\n",
       "       [ 108107.1  ,  113000.   ],\n",
       "       [ 124874.19 ,  118000.   ],\n",
       "       [ 255307.27 ,  237000.   ],\n",
       "       [ 186963.67 ,  173000.   ],\n",
       "       [ 341109.38 ,  395000.   ],\n",
       "       [ 131273.1  ,  127000.   ],\n",
       "       [ 117452.17 ,  110000.   ],\n",
       "       [ 257798.84 ,  311500.   ],\n",
       "       [ 242073.2  ,  245000.   ],\n",
       "       [ 125954.76 ,  119000.   ],\n",
       "       [ 162095.62 ,  145000.   ],\n",
       "       [ 109185.36 ,   84500.   ],\n",
       "       [ 110625.195,  100000.   ],\n",
       "       [ 264670.1  ,  275000.   ],\n",
       "       [ 343855.28 ,  475000.   ],\n",
       "       [ 416637.12 ,  410000.   ],\n",
       "       [ 140094.84 ,  127000.   ],\n",
       "       [ 124626.32 ,  118400.   ],\n",
       "       [ 162007.58 ,  146000.   ],\n",
       "       [ 136261.73 ,  112000.   ],\n",
       "       [ 122738.49 ,  114500.   ],\n",
       "       [ 141192.53 ,  117000.   ],\n",
       "       [ 213662.8  ,  202900.   ],\n",
       "       [ 218198.3  ,  227875.   ],\n",
       "       [ 159303.61 ,  161500.   ],\n",
       "       [ 135605.98 ,  135000.   ],\n",
       "       [ 146055.89 ,  139400.   ],\n",
       "       [ 113632.63 ,  106000.   ],\n",
       "       [ 130876.305,  132500.   ],\n",
       "       [  83008.63 ,   80000.   ],\n",
       "       [ 162302.84 ,  145000.   ],\n",
       "       [ 155818.25 ,  162000.   ],\n",
       "       [ 184549.02 ,  181000.   ],\n",
       "       [  52622.977,   52500.   ],\n",
       "       [ 134599.28 ,  134450.   ],\n",
       "       [ 241620.72 ,  229000.   ],\n",
       "       [  80623.85 ,   68500.   ],\n",
       "       [ 187691.39 ,  185500.   ],\n",
       "       [ 128901.13 ,  137000.   ],\n",
       "       [ 174031.45 ,  168000.   ],\n",
       "       [ 222951.39 ,  238000.   ],\n",
       "       [ 189212.4  ,  182900.   ],\n",
       "       [ 318001.12 ,  284000.   ],\n",
       "       [ 229180.36 ,  205000.   ],\n",
       "       [ 126572.305,  132000.   ],\n",
       "       [ 228563.19 ,  222500.   ],\n",
       "       [ 208497.3  ,  193500.   ],\n",
       "       [ 235188.2  ,  266500.   ],\n",
       "       [ 191964.48 ,  185000.   ],\n",
       "       [ 132416.98 ,  124900.   ],\n",
       "       [ 152772.55 ,  157500.   ],\n",
       "       [ 454116.   ,  426000.   ],\n",
       "       [ 139878.3  ,  140000.   ],\n",
       "       [ 129847.61 ,  118858.   ],\n",
       "       [ 113008.87 ,  109900.   ],\n",
       "       [  96550.48 ,   98000.   ],\n",
       "       [ 740804.94 ,  184750.   ],\n",
       "       [ 109629.09 ,   95000.   ],\n",
       "       [  98947.91 ,   83000.   ],\n",
       "       [1190565.5  ,  160000.   ],\n",
       "       [ 143272.36 ,  138000.   ],\n",
       "       [ 173723.05 ,  190000.   ],\n",
       "       [ 223979.14 ,  225000.   ],\n",
       "       [ 210895.38 ,  200000.   ],\n",
       "       [ 122595.414,  134000.   ],\n",
       "       [ 176955.39 ,  174000.   ],\n",
       "       [ 216312.75 ,  241000.   ],\n",
       "       [ 299168.38 ,  328900.   ],\n",
       "       [ 196988.42 ,  225000.   ],\n",
       "       [ 133894.22 ,  102000.   ],\n",
       "       [ 272829.47 ,  318000.   ],\n",
       "       [ 202644.7  ,  224000.   ],\n",
       "       [ 259689.14 ,  274300.   ],\n",
       "       [ 144549.55 ,  135000.   ],\n",
       "       [ 420976.84 ,  360000.   ],\n",
       "       [ 208219.27 ,  265979.   ],\n",
       "       [ 190803.52 ,  187100.   ],\n",
       "       [ 194520.7  ,  200000.   ],\n",
       "       [ 136531.02 ,  140000.   ],\n",
       "       [ 171209.34 ,  172785.   ]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([net(test_X), test_y[:, np.newaxis]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2960500e+10, 7.2601252e+09, 9.6605000e+09, ..., 4.2049999e+10,\n",
       "       1.9503124e+10, 9.1125002e+09])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(net(train_X), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25913958338.2969"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(161000 - 21.87)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.866129])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(train_X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.866129, 22.09983 , 21.852669, ..., 22.80056 , 22.50327 ,\n",
       "       22.429173])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(train_X).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.296050e+10, 7.260125e+09])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_y[0:2] - net(train_X).squeeze()[0:2])**2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([161000., 120500.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mL2Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Calculates the mean squared error between `label` and `pred`.\n",
       "\n",
       ".. math:: L = \\frac{1}{2} \\sum_i \\vert {label}_i - {pred}_i \\vert^2.\n",
       "\n",
       "`label` and `pred` can have arbitrary shape as long as they have the same\n",
       "number of elements.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "weight : float or None\n",
       "    Global scalar weight for loss.\n",
       "batch_axis : int, default 0\n",
       "    The axis that represents mini-batch.\n",
       "\n",
       "\n",
       "Inputs:\n",
       "    - **pred**: prediction tensor with arbitrary shape\n",
       "    - **label**: target tensor with the same size as pred.\n",
       "    - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
       "      to the same shape as pred. For example, if pred has shape (64, 10)\n",
       "      and you want to weigh each sample in the batch separately,\n",
       "      sample_weight should have shape (64, 1).\n",
       "\n",
       "Outputs:\n",
       "    - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
       "      batch_axis are averaged out.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/loss.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L2Loss?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
